{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# parameters to tune on Eddie\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--seed\", default=\"6202\", help=\"random seed for reproducibility\")\n",
    "\n",
    "parsed_args = parser.parse_args([])\n",
    "# parsed_args = parser.parse_args()\n",
    "parsed_args\n",
    "\n",
    "# fast access parameters\n",
    "validation_mode = False\n",
    "fast_dev_run = True\n",
    "run_on_eddie = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.optim as optim, torch.nn as nn\n",
    "import sys, os\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append(\"./..\") # \\todo: change for relative import\n",
    "from dataset.ASMGMovieLens import ASMGMLDataModule\n",
    "from utils.save import (get_timestamp, save_as_json, get_path_from_re, \n",
    "    append_json_array, load_json_array, get_version)\n",
    "from utils.performance import auc\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from MF.model import get_model, MF\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# filter warning for not setting validation set\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \"Total length of `DataLoader` across ranks is zero.*\")\n",
    "\n",
    "start_time = time()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device = }')\n",
    "\n",
    "# get training regime experiment id\n",
    "# timestamp = get_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# control flow parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    input_path=\"../../data/preprocessed/ml_processed.csv\",\n",
    "    val_start_period=11,\n",
    "    val_end_period=24,\n",
    "    test_start_period=25, # change to None if running as validation\n",
    "    test_end_period=31,  # 25\n",
    "    train_window=10,\n",
    "    seed=int(parsed_args.seed),\n",
    "    model_filename='first_mf',\n",
    "    base_path=None,  # \"../../model/MF/IU/base/220707T162306/first_mf.ckpt\",\n",
    "    save_model=False,\n",
    "    save_result=True\n",
    ")\n",
    "# these are stored on the tensorboard logs\n",
    "model_params = dict(\n",
    "    alias=\"MF\",\n",
    "    n_users=43183,\n",
    "    n_items=51149,\n",
    "    n_latents=8,\n",
    "    l2_regularization_constant=1e-6,\n",
    "    # moved\n",
    "    learning_rate=1e-3,  # 1e-2 is the ASMG MF implementation\n",
    "    batch_size=1024,\n",
    "    n_epochs_offline=20,\n",
    "    n_epochs_online=5,\n",
    "    early_stopping_online=False # train_params[\"test_start_period\"] is None,\n",
    ")\n",
    "train_params[\"model_checkpoint_dir\"] = f'./../../model/{model_params[\"alias\"]}/IU'\n",
    "\n",
    "# in this validation mode no test period is run because we are trying to\n",
    "# infer the number of epochs on the online period\n",
    "if validation_mode:\n",
    "    train_params.update(dict(\n",
    "        test_start_period=None,\n",
    "        test_end_period=None,\n",
    "    ))\n",
    "    model_params.update(dict(\n",
    "        n_epochs_online=30,\n",
    "    ))\n",
    "\n",
    "\n",
    "# saved as json to be able to replicate the experiment\n",
    "experiment_params = {**model_params, **train_params}\n",
    "\n",
    "# ensure fast dev and early stopping are not both true because the logged losses \n",
    "# do not exist\n",
    "assert not (fast_dev_run and model_params[\"early_stopping_online\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training components\n",
    "torch.manual_seed(train_params[\"seed\"])\n",
    "model = get_model(model_params)#.to(device)\n",
    "\n",
    "\n",
    "# progess log\n",
    "progress_bar = TQDMProgressBar(refresh_rate=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_params[\"base_path\"] is None:\n",
    "    \n",
    "    # IU base training\n",
    "\n",
    "    # get model checkpoint path\n",
    "    timestamp = get_timestamp()\n",
    "\n",
    "    # update periods\n",
    "    train_window_begin = train_params[\"val_start_period\"] - train_params[\"train_window\"]\n",
    "    train_window_end = train_params[\"val_start_period\"] - 1\n",
    "    print(\n",
    "        f\"base train periods: {train_window_begin}-{train_window_end}\")\n",
    "\n",
    "    # make checkpoint dir\n",
    "    model_checkpoint_subdir = f'{train_params[\"model_checkpoint_dir\"]}' + (\n",
    "        f'/base/{timestamp}')\n",
    "    if not os.path.exists(model_checkpoint_subdir):\n",
    "        os.makedirs(model_checkpoint_subdir)\n",
    "\n",
    "    base_trainer = Trainer(\n",
    "        accelerator=\"auto\", \n",
    "        devices=1 if (torch.cuda.is_available() or fast_dev_run) else 0,\n",
    "        max_epochs=model_params[\"n_epochs_offline\"],\n",
    "        reload_dataloaders_every_n_epochs=1, enable_checkpointing=False,\n",
    "        default_root_dir=model_checkpoint_subdir, logger=False, callbacks=[\n",
    "            progress_bar], fast_dev_run=fast_dev_run, deterministic=True\n",
    "    )\n",
    "    \n",
    "    # load datsets\n",
    "    train_dm = ASMGMLDataModule(\n",
    "        train_params[\"input_path\"], model_params[\"batch_size\"],\n",
    "        train_window_begin, train_window_end, run_on_eddie=run_on_eddie)\n",
    "\n",
    "    # train\n",
    "    base_trainer.fit(\n",
    "        model, datamodule=train_dm)\n",
    "    print(f\"finished base training\")\n",
    "\n",
    "    # save \n",
    "    train_params[\"base_path\"] = \\\n",
    "        f\"{model_checkpoint_subdir}/{train_params['model_filename']}.ckpt\"\n",
    "    base_trainer.save_checkpoint(train_params[\"base_path\"])\n",
    "    save_as_json(\n",
    "        {**model_params, **train_params}, \n",
    "        train_params[\"base_path\"].replace(\".ckpt\", \"\"))\n",
    "\n",
    "else:\n",
    "    print(\"loading base model at:\", train_params[\"base_path\"])\n",
    "    model = get_model(\n",
    "        experiment_params, return_instance=False).load_from_checkpoint(\n",
    "            checkpoint_path=train_params[\"base_path\"])\n",
    "\n",
    "# ensure reproducibility\n",
    "torch.manual_seed(train_params[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `test_start_period` is used as a lever for use the transfer cycle for\n",
    "# searching hyperparameters\n",
    "if train_params[\"test_start_period\"] is None:\n",
    "\n",
    "    print(\"running online cycle until end of validation\")\n",
    "\n",
    "\n",
    "train_hparams = {\n",
    "    'learning_rate': model_params[\"learning_rate\"],\n",
    "    'l2_regularization_constant': model_params[\"l2_regularization_constant\"]\n",
    "}\n",
    "val_list = []\n",
    "version = None\n",
    "transfer_callbacks = [progress_bar]\n",
    "\n",
    "# IU validation routine\n",
    "for val_period in range(\n",
    "    train_params[\"val_start_period\"] + 1,\n",
    "    train_params[\"val_end_period\"] + 1):\n",
    "\n",
    "    # update periods\n",
    "    train_period = val_period - 1\n",
    "    print(\n",
    "        f\"train period: {train_period}\",\n",
    "        f\"validaton period: {val_period}\", sep=\"\\n\")\n",
    "\n",
    "    # make checkpoint dir\n",
    "    model_checkpoint_subdir = f'{train_params[\"model_checkpoint_dir\"]}/' + (\n",
    "        f'/transfer')\n",
    "    if not os.path.exists(model_checkpoint_subdir):\n",
    "        os.makedirs(model_checkpoint_subdir)\n",
    "\n",
    "    # set logger\n",
    "    version = get_version(\n",
    "        model_checkpoint_subdir) if version is None else version\n",
    "    \n",
    "    if val_period == train_params[\"val_start_period\"] + 1:\n",
    "        print(f\"experiment version: {version}\")\n",
    "    \n",
    "    logger = TensorBoardLogger(model_checkpoint_subdir, version=version,\n",
    "                               sub_dir=f\"V{val_period:02}\")\n",
    "\n",
    "    # save experimet json so it can be replicated\n",
    "    if train_params[\"save_model\"] or train_params[\"save_result\"]:\n",
    "        \n",
    "        # save experimet json only once per training regime execution\n",
    "        if val_period == train_params[\"val_start_period\"] + 1:\n",
    "            save_as_json(\n",
    "                experiment_params, \n",
    "                f'{model_checkpoint_subdir}/{version}'\n",
    "                )\n",
    "\n",
    "    # use early stopping if the script is running for selecting hyperparameters\n",
    "    if model_params[\"early_stopping_online\"]:\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", verbose=True, min_delta=1e-4)\n",
    "        transfer_callbacks.append(early_stopping)\n",
    "\n",
    "    val_trainer = Trainer(\n",
    "        accelerator=\"auto\", \n",
    "        devices=1 if (torch.cuda.is_available() or fast_dev_run) else 0,\n",
    "        max_epochs=model_params[\"n_epochs_online\"],\n",
    "        reload_dataloaders_every_n_epochs=1,\n",
    "        enable_checkpointing=train_params[\"save_model\"],\n",
    "        default_root_dir=model_checkpoint_subdir, logger=logger,\n",
    "        callbacks=transfer_callbacks, enable_model_summary=False,\n",
    "        fast_dev_run=fast_dev_run, deterministic=True)\n",
    "\n",
    "    # load datsets\n",
    "    train_dm = ASMGMLDataModule(\n",
    "        train_params[\"input_path\"], model_params[\"batch_size\"],\n",
    "        train_period, period_val=val_period, run_on_eddie=run_on_eddie)\n",
    "\n",
    "    # train\n",
    "    val_trainer.fit(\n",
    "        model, datamodule=train_dm)\n",
    "    print(f\"finished val_period {val_period}\")\n",
    "\n",
    "    # log hyperparameters according to transfer period mode\n",
    "    val_score = (\n",
    "        early_stopping.best_score if model_params[\n",
    "            \"early_stopping_online\"] else val_trainer.logged_metrics[\n",
    "                \"val_loss\"]).item()\n",
    "    n_epochs_dict = {}\n",
    "    if model_params[\"early_stopping_online\"]:\n",
    "        n_epochs_dict[\"n_epochs_online\"] = val_trainer.current_epoch - (\n",
    "            early_stopping.patience)\n",
    "    val_trainer.logger.log_hyperparams(\n",
    "        {\n",
    "            **model_params,\n",
    "            **n_epochs_dict\n",
    "        },\n",
    "        metrics=val_score)\n",
    "\n",
    "    val_list.append({\n",
    "        \"period\": val_period,\n",
    "        **model_params,\n",
    "        \"val_loss\": val_score})\n",
    "\n",
    "else:\n",
    "    # save validation results\n",
    "    val_df = pd.DataFrame(val_list)\n",
    "    average_srs = val_df.mean()\n",
    "    average_srs.at[\"period\"] = \"mean\"\n",
    "    print(average_srs)\n",
    "    val_df_path = f'{model_checkpoint_subdir}/{version}.csv'\n",
    "    if train_params[\"save_result\"]:\n",
    "        pd.concat((val_df, average_srs.to_frame().T), axis=0, ignore_index=True\n",
    "                  ).to_csv(val_df_path, index=False)\n",
    "        print(f\"saved results csv at: {os.path.abspath(val_df_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_params[\"test_start_period\"] is not None:\n",
    "\n",
    "    # initialize results container\n",
    "    res_dict = defaultdict(lambda: [])\n",
    "\n",
    "    print(\"running online cycles until end of test\")\n",
    "    \n",
    "    # BU test routine\n",
    "    for test_period in range(\n",
    "        train_params[\"test_start_period\"], train_params[\"test_end_period\"] + 1):\n",
    "\n",
    "        # update periods\n",
    "        train_period = test_period - 1 \n",
    "        print(\n",
    "            f\"train periods: {train_window_begin}-{train_window_end}\", \n",
    "            f\"test period: {test_period}\", sep=\"\\n\")\n",
    "\n",
    "        # make checkpoint dir\n",
    "        model_checkpoint_subdir = f'{train_params[\"model_checkpoint_dir\"]}' + (\n",
    "            f'/T{test_period:02}' if train_params[\"save_model\"] else \"\")\n",
    "        if not os.path.exists(model_checkpoint_subdir):\n",
    "            os.makedirs(model_checkpoint_subdir) \n",
    "\n",
    "        # model_checkpoint_path = f'{model_checkpoint_subdir}/' \\\n",
    "        #     f'{train_params[\"model_filename_stem\"]}.pth'\n",
    "\n",
    "        test_trainer = Trainer(\n",
    "            accelerator=\"auto\", \n",
    "            devices=1 if (torch.cuda.is_available() or fast_dev_run) else 0,\n",
    "            max_epochs=model_params[\"n_epochs_online\"], reload_dataloaders_every_n_epochs=1,\n",
    "            enable_checkpointing=train_params[\"save_model\"],\n",
    "            default_root_dir=model_checkpoint_subdir,\n",
    "            logger=False, enable_model_summary=False,\n",
    "            callbacks=[progress_bar], fast_dev_run = fast_dev_run, \n",
    "            deterministic=True\n",
    "        )\n",
    "\n",
    "        # load datsets \n",
    "        train_dm = ASMGMLDataModule(\n",
    "            train_params[\"input_path\"], model_params[\"batch_size\"], \n",
    "            train_period, run_on_eddie=run_on_eddie)\n",
    "        test_dm = ASMGMLDataModule(\n",
    "            train_params[\"input_path\"], model_params[\"batch_size\"], test_period,\n",
    "            run_on_eddie=run_on_eddie)\n",
    "\n",
    "        # train\n",
    "        start_training_time = time()\n",
    "        test_trainer.fit(\n",
    "            model, datamodule=train_dm)\n",
    "        res_dict[\"train_time\"].append(time() - start_training_time)\n",
    "        res_dict[\"period\"].append(test_period)\n",
    "        res_dict[\"trainLoss\"].append(test_trainer.logged_metrics[\"train_loss\"].item())\n",
    "        print(f\"finished test_period {test_period}\")\n",
    "\n",
    "        # get test loss\n",
    "        test_trainer.test(model, datamodule=test_dm)\n",
    "        res_dict[\"loss\"].append(test_trainer.logged_metrics[\"test_loss\"].item())\n",
    "\n",
    "        # get test AUC\n",
    "        with torch.no_grad():\n",
    "            test_auc = auc(model, test_dm.test_dataset.y, test_dm.test_dataloader(), \n",
    "                model_params[\"batch_size\"])\n",
    "        res_dict[\"auc\"].append(test_auc)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        timestamp = get_timestamp()\n",
    "        df_path = f\"{model_checkpoint_subdir.replace(f'/T{test_period:02}', '')}/{version}.csv\"\n",
    "        df_path\n",
    "\n",
    "        # calculate and display average loss\n",
    "        res_df = pd.DataFrame(res_dict)\n",
    "\n",
    "        average_srs = res_df.mean()\n",
    "        average_srs.at[\"period\"] = \"mean\"\n",
    "        print(average_srs)\n",
    "\n",
    "        if train_params[\"save_result\"]: \n",
    "            pd.concat((res_df, average_srs.to_frame().T), axis=0, ignore_index=True\n",
    "            ).to_csv(df_path, index=False)\n",
    "            print(f\"saved results csv at: {os.path.abspath(df_path)}\")\n",
    "\n",
    "else:\n",
    "    print(\"skipped test cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save master results\n",
    "results_master_path = train_params[\"model_checkpoint_dir\"] + \"/results.json\"\n",
    "\n",
    "# concatenate summary results and script args\n",
    "res_dict = average_srs.to_dict()\n",
    "res_dict.update(**vars(parsed_args), **{\n",
    "    \"n_epochs_on_test\": model_params[\"n_epochs_offline\"],\n",
    "    \"timestamp\": timestamp,\n",
    "    \"version\": version,\n",
    "    })\n",
    "print(res_dict)\n",
    "append_json_array(res_dict, results_master_path)\n",
    "load_json_array(results_master_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total elapsed time: {(time() - start_time) / 3600:.2f} hrs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('alpha')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ae111bd7481dd6266ac7e84bf867498b6b0fbfa14667d050bcdd9b0494c793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
