{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "### update 15/08\n",
    "validation_mode implies the models runs in validation + test set, selecting the median number of epochs from the validation period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# parameters to tune on Eddie\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--seed\", default=\"6202\", help=\"random seed for reproducibility\")\n",
    "\n",
    "parsed_args = parser.parse_args([])\n",
    "# parsed_args = parser.parse_args()\n",
    "parsed_args\n",
    "\n",
    "# fast access parameters\n",
    "validation_mode = True\n",
    "fast_dev_run = True\n",
    "run_on_eddie = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.optim as optim, torch.nn as nn\n",
    "import sys, os\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append(\"./..\") # \\todo: change for relative import\n",
    "from dataset.ASMGMovieLens import ASMGMLDataModule\n",
    "from utils.save import (get_timestamp, save_as_json, get_path_from_re, \n",
    "    append_json_array, load_json_array)\n",
    "from utils.performance import auc\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from MF.model import get_model\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# filter warning for not setting validation set\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \"Total length of `DataLoader` across ranks is zero.*\")\n",
    "\n",
    "start_time = time()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device = }')\n",
    "\n",
    "# get training regime experiment id\n",
    "# timestamp = get_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    input_path=\"../../data/preprocessed/ml_processed.csv\",\n",
    "    validation_start_period=None,\n",
    "    validation_end_period=None,\n",
    "    test_start_period=25,\n",
    "    test_end_period=31,  # 25,\n",
    "    train_window=10,\n",
    "    batch_size=1024,\n",
    "    learning_rate=1e-3,  # 1e-2 is the ASMG MF implementation\n",
    "    model_filename_stem='first_mf',\n",
    "    seed=int(parsed_args.seed),\n",
    "    save_model=False,\n",
    "    save_result=True,\n",
    "    save_predictions=True,\n",
    ")\n",
    "model_params = dict(\n",
    "    alias=\"MF\",\n",
    "    n_users=43183,\n",
    "    n_items=51149,\n",
    "    n_latents=8,\n",
    "    l2_regularization_constant=1e-6,\n",
    "    n_epochs_offline=20,\n",
    ")\n",
    "train_params[\"model_checkpoint_dir\"] = f'./../../model/{model_params[\"alias\"]}/BM'\n",
    "\n",
    "if validation_mode:\n",
    "    train_params.update(dict(\n",
    "        validation_start_period=11,\n",
    "        validation_end_period=24,\n",
    "    ))\n",
    "    model_params.update(dict(\n",
    "        n_epochs_offline=40,\n",
    "    ))\n",
    "\n",
    "# ensure compatibility with IU model implementation\n",
    "model_params.update(dict(\n",
    "    n_epochs_online=None,\n",
    "    early_stopping_online=None\n",
    "))\n",
    "\n",
    "# get timestamp\n",
    "timestamp = get_timestamp()\n",
    "\n",
    "params = argparse.Namespace(**train_params, **model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize results containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training components\n",
    "torch.manual_seed(train_params[\"seed\"])\n",
    "model = get_model({**model_params, **train_params})\n",
    "\n",
    "# progess log\n",
    "progress_bar = TQDMProgressBar(refresh_rate=200)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=False, \n",
    "    min_delta=1e-4, patience=5)\n",
    "\n",
    "# initialize results container\n",
    "res_dict = defaultdict(lambda: [])\n",
    "val_dict = defaultdict(lambda: [])\n",
    "\n",
    "# initialize dict of hyperparameters\n",
    "train_hparams = {\n",
    "    'learning_rate': train_params[\"learning_rate\"],\n",
    "    'l2_regularization_constant': model_params[\n",
    "        \"l2_regularization_constant\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_params[\"validation_start_period\"] is not None:\n",
    "\n",
    "    # BU validation regime routine\n",
    "    for val_period in range(\n",
    "        train_params[\"validation_start_period\"], \n",
    "        train_params[\"validation_end_period\"] + 1):\n",
    "\n",
    "        # update periods\n",
    "        train_window_begin = val_period - train_params[\"train_window\"]\n",
    "        train_window_end = val_period - 1\n",
    "        print(\n",
    "            f\"train periods: {train_window_begin}-{train_window_end}\",\n",
    "            f\"test period: {val_period}\", sep=\"\\n\")\n",
    "\n",
    "        # make checkpoint dir\n",
    "        model_checkpoint_subdir = f'{train_params[\"model_checkpoint_dir\"]}/' + (\n",
    "            f'/V{val_period:02}')\n",
    "        if not os.path.exists(model_checkpoint_subdir):\n",
    "            os.makedirs(model_checkpoint_subdir)\n",
    "\n",
    "        val_trainer = Trainer(\n",
    "            accelerator=\"auto\", \n",
    "            devices=1 if (torch.cuda.is_available() or fast_dev_run) else 0,\n",
    "            max_epochs=model_params[\"n_epochs_offline\"], reload_dataloaders_every_n_epochs=1,\n",
    "            enable_checkpointing=train_params[\"save_model\"],\n",
    "            default_root_dir=model_checkpoint_subdir,\n",
    "            enable_model_summary=(\n",
    "                True if val_period == train_params[\"validation_start_period\"]\n",
    "                else False),\n",
    "            callbacks=[\n",
    "                early_stopping, progress_bar], deterministic=True,\n",
    "            fast_dev_run=fast_dev_run\n",
    "        )\n",
    "\n",
    "        # load datsets\n",
    "        train_dm = ASMGMLDataModule(\n",
    "            train_params[\"input_path\"], train_params[\"batch_size\"],\n",
    "            train_window_begin, train_window_end, period_val=val_period,\n",
    "            run_on_eddie=run_on_eddie)\n",
    "\n",
    "        # train\n",
    "        val_trainer.fit(\n",
    "            model, datamodule=train_dm)\n",
    "        print(f\"finished val_period {val_period}\")\n",
    "\n",
    "        # log hyperparameters\n",
    "        ran_epochs = val_trainer.current_epoch - (\n",
    "            0 if fast_dev_run else early_stopping.patience)\n",
    "        val_trainer.logger.log_hyperparams({\n",
    "            **train_hparams,\n",
    "            'n_epochs': ran_epochs\n",
    "        }, metrics=early_stopping.best_score)\n",
    "\n",
    "        # save optimal number of epochs \n",
    "        val_dict[\"n_epochs\"].append(ran_epochs)\n",
    "\n",
    "        torch.manual_seed(train_params[\"seed\"])\n",
    "        model.reset_parameters()\n",
    "\n",
    "    # end of for loop\n",
    "    else:\n",
    "\n",
    "        # define where to save master results\n",
    "        val_master_path = train_params[\"model_checkpoint_dir\"] + \"/val.json\"\n",
    "\n",
    "        # concatenate summary results and script args\n",
    "        val_dict.update(**vars(parsed_args), **{\n",
    "            \"average_epochs\": np.mean(val_dict[\"n_epochs\"]),\n",
    "            \"timestamp\": timestamp\n",
    "            })\n",
    "        print(val_dict)\n",
    "        append_json_array(val_dict, val_master_path)\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"skipped validation cycle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproducibility\n",
    "torch.manual_seed(train_params[\"seed\"])\n",
    "\n",
    "if train_params[\"test_start_period\"] is not None:\n",
    "\n",
    "    if train_params[\"validation_start_period\"] is not None:\n",
    "        optimal_epochs = int(round(pd.Series(val_dict[\"n_epochs\"]).mean(), 0))\n",
    "    else:\n",
    "        optimal_epochs = model_params[\"n_epochs_offline\"]\n",
    "    \n",
    "    # BU test routine\n",
    "    for test_period in range(\n",
    "        train_params[\"test_start_period\"], train_params[\"test_end_period\"] + 1):\n",
    "\n",
    "        # update periods\n",
    "        train_window_begin = test_period - train_params[\"train_window\"]\n",
    "        train_window_end = test_period - 1 \n",
    "        print(\n",
    "            f\"train periods: {train_window_begin}-{train_window_end}\", \n",
    "            f\"test period: {test_period}\", sep=\"\\n\")\n",
    "\n",
    "        # make checkpoint dir\n",
    "        model_checkpoint_subdir = f'{train_params[\"model_checkpoint_dir\"]}' + (\n",
    "            f'/T{test_period:02}' if (\n",
    "                train_params[\"save_model\"] or params.save_predictions) else \"\")\n",
    "        if not os.path.exists(model_checkpoint_subdir):\n",
    "            os.makedirs(model_checkpoint_subdir) \n",
    "\n",
    "        # model_checkpoint_path = f'{model_checkpoint_subdir}/' \\\n",
    "        #     f'{train_params[\"model_filename_stem\"]}.pth'\n",
    "        test_trainer = Trainer(\n",
    "            accelerator=\"auto\", \n",
    "            devices=1 if (torch.cuda.is_available() or fast_dev_run) else 0,\n",
    "            max_epochs=optimal_epochs, reload_dataloaders_every_n_epochs=1,\n",
    "            enable_checkpointing=train_params[\"save_model\"],\n",
    "            default_root_dir=model_checkpoint_subdir,\n",
    "            logger=False, enable_model_summary=False,\n",
    "            callbacks=[progress_bar], deterministic=True, \n",
    "            fast_dev_run=fast_dev_run\n",
    "        )\n",
    "\n",
    "        # load datsets \n",
    "        train_dm = ASMGMLDataModule(\n",
    "            train_params[\"input_path\"], train_params[\"batch_size\"], \n",
    "            train_window_begin, train_window_end, run_on_eddie=run_on_eddie)\n",
    "        test_dm = ASMGMLDataModule(\n",
    "            train_params[\"input_path\"], train_params[\"batch_size\"], test_period,\n",
    "            run_on_eddie=run_on_eddie)\n",
    "\n",
    "        # train\n",
    "        start_training_time = time()\n",
    "        test_trainer.fit(\n",
    "            model, datamodule=train_dm)\n",
    "        res_dict[\"train_time\"].append(time() - start_training_time)\n",
    "        res_dict[\"period\"].append(test_period)\n",
    "        res_dict[\"trainLoss\"].append(test_trainer.logged_metrics[\"train_loss\"].item())\n",
    "        print(f\"finished test_period {test_period}\")\n",
    "\n",
    "        # get test loss\n",
    "        test_trainer.test(model, datamodule=test_dm)\n",
    "        res_dict[\"loss\"].append(test_trainer.logged_metrics[\"test_loss\"].item())\n",
    "\n",
    "        # get test AUC and save predictions\n",
    "        predictions_path = f'{model_checkpoint_subdir}/preds-s{params.seed}.pt'\n",
    "        with torch.no_grad():\n",
    "            test_auc = auc(model, test_dm.test_dataset.y, test_dm.test_dataloader(), \n",
    "                train_params[\"batch_size\"], \n",
    "                prediction_dst=(\n",
    "                    predictions_path if params.save_predictions else None))\n",
    "        res_dict[\"auc\"].append(test_auc)\n",
    "\n",
    "        torch.manual_seed(train_params[\"seed\"])\n",
    "        model.reset_parameters()\n",
    "        \n",
    "    else:\n",
    "        df_path = f\"{model_checkpoint_subdir.replace(f'/T{test_period:02}', '')}/{timestamp}.csv\"\n",
    "        df_path\n",
    "\n",
    "        # calculate and display average loss\n",
    "        res_df = pd.DataFrame(res_dict)\n",
    "\n",
    "        average_srs = res_df.mean()\n",
    "        average_srs.at[\"period\"] = \"mean\"\n",
    "        print(average_srs)\n",
    "\n",
    "        if train_params[\"save_result\"]: \n",
    "            pd.concat((res_df, average_srs.to_frame().T), axis=0, ignore_index=True\n",
    "            ).to_csv(df_path, index=False)\n",
    "            print(f\"saved results csv at: {os.path.abspath(df_path)}\")\n",
    "            \n",
    "        # define where to save master results\n",
    "        results_master_path = train_params[\"model_checkpoint_dir\"] + \"/results.json\"\n",
    "\n",
    "        # concatenate summary results and script args\n",
    "        res_dict = average_srs.to_dict()\n",
    "        res_dict.update(**vars(parsed_args), **{\n",
    "            \"n_epochs_on_test\": model_params[\"n_epochs_offline\"],\n",
    "            \"timestamp\": timestamp\n",
    "            })\n",
    "        print(res_dict)\n",
    "        append_json_array(res_dict, results_master_path)\n",
    "        load_json_array(results_master_path)\n",
    "        print(f\"Total elapsed time: {(time() - start_time) / 3600:.2f} hrs.\")\n",
    "\n",
    "else:\n",
    "    print(\"skipped test cycle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('alpha')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ae111bd7481dd6266ac7e84bf867498b6b0fbfa14667d050bcdd9b0494c793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
