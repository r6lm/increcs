{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save import load_json_array, print_latex\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob, argparse\n",
    "import sys\n",
    "sys.path.append(\"./..\") # \\todo: change for relative import\n",
    "from dataset.ASMGMovieLens import ASMGMovieLens\n",
    "from collections import defaultdict\n",
    "import psutil\n",
    "import os\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# # parser.add_argument(\n",
    "# #     \"--regime\", default=\"BM\", help=\"training regime for whih results are collected\")\n",
    "# parser.add_argument(\n",
    "#     \"--eddie\", default=\"1\", choices=[f\"{i}\" for i in range(2)],\n",
    "#     help=\"training regime for whih results are collected\")\n",
    "\n",
    "# parsed_args = parser.parse_args([\"--eddie\", \"0\"])\n",
    "# # parsed_args = parser.parse_args()\n",
    "\n",
    "# run_on_eddie = bool(int(parsed_args.eddie))\n",
    "\n",
    "params_dict = dict(\n",
    "    lightning_seeds=range(1, 6),\n",
    "    regimes=(\"BM\", \"IU\", \"BIU\", \"SML\"),\n",
    "    input_path = \"../data/preprocessed/ml_processed.csv\",\n",
    "    # tyxe_dir=\"/home/s2110626/diss/TyXe\",\n",
    "    # tyxe_versions=range(73, 78),\n",
    "    preds_dir=\"../safebox/preds\",\n",
    "    start_test_period = 25,\n",
    "    end_test_period = 31\n",
    ")\n",
    "# if not run_on_eddie:\n",
    "#     params_dict.update(dict(\n",
    "#         lightning_seeds = [6202],\n",
    "#         tyxe_versions = [60],\n",
    "#         tyxe_dir=\"../\"\n",
    "#     ))\n",
    "\n",
    "params = argparse.Namespace(**params_dict)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Generalization Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in range(1,6):\n",
    "def mean_se_log(concat_prob_correct):\n",
    "    prob_correct_clean = concat_prob_correct[concat_prob_correct != 0]\n",
    "    print(f\"predictions completely wrong: {len(concat_prob_correct) - len(prob_correct_clean)}\")\n",
    "    log_prob_correct = torch.log(prob_correct_clean)\n",
    "    std_log, mean_log = torch.std_mean(log_prob_correct)\n",
    "    se_log = std_log / np.sqrt(len(prob_correct_clean))\n",
    "    return mean_log,se_log\n",
    "\n",
    "summary_dict = {}\n",
    "preds_dict = defaultdict(lambda: [])\n",
    "pred_labels_dict = defaultdict(lambda: [])\n",
    "\n",
    "for regime in params.regimes:\n",
    "    print(f\"{regime =}\")\n",
    "\n",
    "    # initialize containers \n",
    "    mc_means = []\n",
    "    mc_se = []\n",
    "\n",
    "    # get y_true and global parameters\n",
    "    concat_true_y = ASMGMovieLens(\n",
    "        params.input_path, params.start_test_period, \n",
    "        params.end_test_period).y\n",
    "    n_periods = params.end_test_period - params.start_test_period + 1\n",
    "    obs_per_period = int(len(concat_true_y) / n_periods)\n",
    "\n",
    "    # if regime != \"BIU\":\n",
    "        # iterate_in = params.lightning_seeds\n",
    "\n",
    "    # else: \n",
    "    #     iterate_in = params.tyxe_versions\n",
    "\n",
    "    for seed in params.lightning_seeds:\n",
    "\n",
    "        print(f\"{seed = }\")\n",
    "\n",
    "        # concatenate results\n",
    "        concat_prob_correct = torch.ones_like(concat_true_y) * -1\n",
    "        concat_pred_label_y = torch.ones_like(concat_true_y, dtype=bool)\n",
    "        for i, test_period in enumerate(range(\n",
    "            params.start_test_period, params.end_test_period + 1)):\n",
    "\n",
    "            # get preds filename\n",
    "            # if regime != \"BIU\":\n",
    "            #     filename = (\n",
    "            #         f\"../model/MF/{regime}/T{test_period}/preds-s\"\n",
    "            #         f\"{seed_or_version}.pt\")\n",
    "            # else:\n",
    "            #     filenm_pattern = (\n",
    "            #         f\"{params.tyxe_dir}/model/MF/mean-field/version_\"\n",
    "            #         f\"{seed_or_version}/T{test_period}/preds-s*.pt\")\n",
    "            #     matching_files = glob.glob(filenm_pattern)\n",
    "            #     assert len(matching_files) == 1, (\n",
    "            #         \"More than 1 file matches the pattern\")\n",
    "            #     filename = matching_files[0]\n",
    "\n",
    "            filename = os.path.join(\n",
    "                    params.preds_dir, regime, f\"T{test_period}\", f\"preds-s{seed}\")\n",
    "            try:\n",
    "                pred_y = torch.load(f\"{filename}.pt\")\n",
    "            except FileNotFoundError:\n",
    "                pred_y = torch.tensor(np.load(f\"{filename}.npy\"))\n",
    "\n",
    "            # obtain accuracy\n",
    "            pred_label_y = torch.round(pred_y)\n",
    "            concat_pred_label_y[\n",
    "                i * obs_per_period:(i + 1) * obs_per_period\n",
    "            ] = pred_label_y\n",
    "\n",
    "            # obtain probability of correct prediction\n",
    "            true_y = concat_true_y[i * obs_per_period:(i + 1) * obs_per_period]\n",
    "            prob_correct = pred_y\n",
    "            prob_correct[~true_y.bool()] = 1 - prob_correct[~true_y.bool()]\n",
    "            concat_prob_correct[\n",
    "                i * obs_per_period:(i + 1) * obs_per_period\n",
    "            ] = prob_correct\n",
    "\n",
    "        assert (concat_prob_correct != -1).all().item()\n",
    "\n",
    "        mean_log, se_log = mean_se_log(concat_prob_correct)\n",
    "        mc_means.append(- mean_log.item())\n",
    "        mc_se.append(se_log.item())\n",
    "        preds_dict[regime].append(concat_prob_correct)\n",
    "        pred_labels_dict[regime].append(concat_pred_label_y)\n",
    "\n",
    "    summary_dict.update({\n",
    "        (regime, \"mean\"): mc_means,\n",
    "        (regime, \"se\"): mc_se\n",
    "    })\n",
    "\n",
    "    gen_error = np.mean(mc_means)\n",
    "    gen_error_se = np.mean(mc_se)\n",
    "    print(f\"generalization error: {gen_error:.4f} ± {gen_error_se:.4f}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(summary_dict).to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_error_df = pd.DataFrame(summary_dict)\n",
    "gen_error_df.mean(0), gen_error_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_error_df\n",
    "gen_error_srs = gen_error_df.mean(0).unstack().round(5).agg(\n",
    "    lambda srs: f\"{srs.iloc[0]} ± {srs.iloc[1]}\", axis=1)\n",
    "gen_error_srs.name = \"gen. error [NLL]\"\n",
    "\n",
    "expected_gen_error_srs = gen_error_df.mean(0).unstack()[\"mean\"]\n",
    "# expected_gen_error_srs = pd.Series({k: (v.sum() / len(v)).item() for k, v in cat_labels_dict.items()})\n",
    "# expected_gen_error_srs.name = \"accuracy\"\n",
    "gen_error_diff = expected_gen_error_srs.subtract(expected_gen_error_srs[\"BM\"])\n",
    "gen_error_diff.name = \"difference\"\n",
    "perc_diff = expected_gen_error_srs.div(expected_gen_error_srs[\"BM\"]).subtract(1).mul(-100).round(2).astype(\"str\") + \"%\"\n",
    "perc_diff.name = \"imp%\"\n",
    "accuracy_table = pd.concat([gen_error_srs, gen_error_diff.round(5), perc_diff], axis=1)\n",
    "\n",
    "# rename training regimes\n",
    "tr_dict = dict(zip(['BIU', 'BM', 'IU', 'SML'], ['BIFT', 'PBT', 'IFT', 'SML']))\n",
    "accuracy_table = accuracy_table.rename(tr_dict)\n",
    "\n",
    "print_latex(accuracy_table.iloc[[1, 2, 0, 3]], column_format=\"lccc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss\")\n",
    "cat_loss_dict = {k: - torch.log(torch.stack(v, axis=1)).mean(1) for k, v in preds_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k1, k2 in combinations(cat_loss_dict, 2):\n",
    "    print(\"\\n\", k1, k2)\n",
    "    print(\"greater\")\n",
    "    print(wilcoxon(cat_loss_dict[k1], cat_loss_dict[k2], alternative=\"greater\"))\n",
    "    print(\"less\")\n",
    "    print(wilcoxon(cat_loss_dict[k1], cat_loss_dict[k2], alternative=\"less\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1, k2 in combinations(cat_loss_dict, 2):\n",
    "    print(\"\\n\", k1, k2)\n",
    "    print(\"greater\")\n",
    "    print(ttest_rel(cat_loss_dict[k1], cat_loss_dict[k2], alternative=\"greater\"))\n",
    "    print(\"less\")\n",
    "    print(ttest_rel(cat_loss_dict[k1], cat_loss_dict[k2], alternative=\"less\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy\")\n",
    "# correct\n",
    "cat_labels_dict = {\n",
    "    k: torch.stack(v, axis=1).mode(1)[0] == concat_true_y.bool() for k, v in pred_labels_dict.items()\n",
    "    # k: torch.cat([ypred == concat_true_y.bool() for ypred in v]).int(\n",
    "    # ) for k, v in pred_labels_dict.items()}\n",
    "}\n",
    "cat_labels_dict[\"SML\"]\n",
    "# labels\n",
    "# cat_labels_dict = {\n",
    "#     k: torch.cat(v).int() for k, v in pred_labels_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_srs = pd.Series({k: (v.sum() / len(v)).item() for k, v in cat_labels_dict.items()})\n",
    "accuracy_srs.name = \"accuracy\"\n",
    "accuracy_diff = accuracy_srs.subtract(accuracy_srs[\"BM\"])\n",
    "accuracy_diff.name = \"difference\"\n",
    "perc_diff = accuracy_srs.div(accuracy_srs[\"BM\"]).subtract(1).mul(100).round(2).astype(\"str\") + \"%\"\n",
    "perc_diff.name = \"% imp\"\n",
    "accuracy_table = pd.concat([accuracy_srs.round(4), accuracy_diff.round(4), perc_diff], axis=1)\n",
    "\n",
    "# rename training regimes\n",
    "tr_dict = dict(zip(['BIU', 'BM', 'IU', 'SML'], ['BIFT', 'PBT', 'IFT', 'SML']))\n",
    "accuracy_table = accuracy_table.rename(tr_dict)\n",
    "\n",
    "print_latex(accuracy_table, column_format=\"lccc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k1, k2 in combinations(cat_labels_dict, 2):\n",
    "    print(\"\\n\", k1, k2)\n",
    "    table = pd.crosstab(pd.Series(cat_labels_dict[k1]).astype(\n",
    "        \"category\"), pd.Series(cat_labels_dict[k2]).astype(\"category\"))\n",
    "    # stat, p = \n",
    "    print(mcnemar(table.values, exact=False, correction=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = os.getpid()\n",
    "python_process = psutil.Process(pid)\n",
    "memoryUse = python_process.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "print('memory use:', memoryUse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('alpha')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ae111bd7481dd6266ac7e84bf867498b6b0fbfa14667d050bcdd9b0494c793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
